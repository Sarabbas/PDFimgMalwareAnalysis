{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing libs"
      ],
      "metadata": {
        "id": "GN9crajHdurt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Z1AK28EAdb7U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a14f2c6b-db8c-47a0-b199-ab53ffb096fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !git clone 'https://github.com/aaronanderson99/MalCompare.git'"
      ],
      "metadata": {
        "id": "3KsLK7S-dot8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scipy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKDsc82QoNzy",
        "outputId": "cfb2a998-8a15-45f2-9f7d-c9f175eb9889"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from scipy) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "#####\n",
        "import numpy as np\n",
        "#import scipy.misc as smp # Save images\n",
        "import scipy.ndimage as snd # Load images\n",
        "import math # Aids \"length\" variable\n",
        "import progressbar as pb\n",
        "from math import isinf\n",
        "import os\n",
        "import gc\n",
        "####\n",
        "\n",
        "from multiprocessing import Pool\n",
        "\n",
        "import scipy.misc as smp # Save images\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import cv2 # (ORB, SIFT, cvtColor(grey))\n",
        "from scipy import ndimage as nd # For convolving kernel\n",
        "from skimage import exposure # For creating histogram\n",
        "from skimage.util import img_as_float # Needed for gabor filter\n",
        "from skimage.feature import local_binary_pattern\n",
        "from skimage.filters import gabor_kernel\n",
        "from skimage.filters.rank import entropy\n",
        "from skimage.morphology import disk # Create a disk around a pixel (for entropy)\n",
        "\n",
        "####################\n",
        "\n",
        "\n",
        "import random\n",
        "\n",
        "# ML Classifiers\n",
        "from sklearn import svm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Model evaluation\n",
        "from sklearn.model_selection import cross_validate\n",
        "import sklearn.metrics as skm\n",
        "\n",
        "import imageio\n",
        "import PIL\n",
        "import shutil\n"
      ],
      "metadata": {
        "id": "-2llnRA7dsL3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Directories"
      ],
      "metadata": {
        "id": "QO3A7o4_DJob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# for filee in os.listdir('/content/drive/MyDrive/SEproject/Phase3/Contagio/CLEAN_PDF_9000_files'):\n",
        "# \tsrc=os.path.join(\"/content/drive/MyDrive/SEproject/Phase3/Contagio/CLEAN_PDF_9000_files\",filee)\n",
        "# \tdst=f\"/content/drive/MyDrive/SEproject/Phase3/Contagio/CLEAN_PDF_9000_files/CLEAN_{filee}\"\n",
        "# \tos.rename(src, dst)\n",
        "# \t#shutil.copy(os.path.join(path_of_files_folders, filee), destination)\n",
        "# #os.rename('/content/drive/MyDrive/SEproject/Phase3/Contagio/CLEAN_PDF_9000_files/CLEAN_0_ea-2a_1108.pdf','/content/drive/MyDrive/SEproject/Phase3/Contagio/CLEAN_PDF_9000_files/0_ea-2a_1108.pdf')"
      ],
      "metadata": {
        "id": "jQGMNtaCH7Q8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# for filee in os.listdir('/content/drive/MyDrive/SEproject/Phase3/Contagio/MALWARE_PDF_PRE_04-2011_10982_files'):\n",
        "# \tsrc=os.path.join(\"/content/drive/MyDrive/SEproject/Phase3/Contagio/MALWARE_PDF_PRE_04-2011_10982_files\",filee)\n",
        "# \tdst=f\"/content/drive/MyDrive/SEproject/Phase3/Contagio/MALWARE_PDF_PRE_04-2011_10982_files/INFEC_{filee}\"\n",
        "# \tos.rename(src, dst)"
      ],
      "metadata": {
        "id": "566hWMe7bLv-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   Train: 10,500 file (5,250 benign & 5,250 malicious)\n",
        "*   Test: 4,500 file (2,250 benign & 2,250 malicious)\n",
        "\n",
        "*  Total dataset: 15,000 with a 70:30 split\n"
      ],
      "metadata": {
        "id": "3JBR-rbFzyX2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train 70%"
      ],
      "metadata": {
        "id": "BHjmwZ_A0IaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Benign\n",
        "\n",
        "# c=0\n",
        "# for c,filee in enumerate(os.listdir('/content/drive/MyDrive/SEproject/Phase3/Contagio/CLEAN_PDF_9000_files')):\n",
        "#   if filee.endswith(\".png\"):\n",
        "#     src=os.path.join(\"/content/drive/MyDrive/SEproject/Phase3/Contagio/CLEAN_PDF_9000_files\",filee)\n",
        "#     dst=\"/content/drive/MyDrive/SEproject/Phase3/Contagio/Train\"\n",
        "#     shutil.copy(src, dst)\n",
        "#   if c==5250:\n",
        "#     break\n",
        "\n",
        "# print(c)"
      ],
      "metadata": {
        "id": "_wO6gW2l0DDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #Malicious\n",
        "# c=0\n",
        "# for c,filee in enumerate(os.listdir('/content/drive/MyDrive/SEproject/Phase3/Contagio/MALWARE_PDF_PRE_04-2011_10982_files')):\n",
        "#   if filee.endswith(\".png\"):\n",
        "#     src=os.path.join(\"/content/drive/MyDrive/SEproject/Phase3/Contagio/MALWARE_PDF_PRE_04-2011_10982_files\",filee)\n",
        "#     dst=\"/content/drive/MyDrive/SEproject/Phase3/Contagio/Train\"\n",
        "#     shutil.copy(src, dst)\n",
        "#     if c==5250:\n",
        "#       break"
      ],
      "metadata": {
        "id": "hlWNWTvB0Fxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test 30%"
      ],
      "metadata": {
        "id": "JHGVCzCt0Jv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# for c,filee in reversed(list(enumerate(os.listdir('/content/drive/MyDrive/SEproject/Phase3/Contagio/CLEAN_PDF_9000_files')))):\n",
        "#     if filee.endswith(\".png\"):\n",
        "#       src=os.path.join(\"/content/drive/MyDrive/SEproject/Phase3/Contagio/CLEAN_PDF_9000_files\",filee)\n",
        "#       TestPath=\"/content/drive/MyDrive/SEproject/Phase3/Contagio/Test\"\n",
        "#       TrainPath=\"/content/drive/MyDrive/SEproject/Phase3/Contagio/Train\"\n",
        "#       if os.path.exists(os.path.join(TestPath,filee))==False and os.path.exists(os.path.join(TestPath,filee))==False:\n",
        "#         shutil.copy(src, TestPath)\n",
        "#     if c==6750:\n",
        "#       break\n"
      ],
      "metadata": {
        "id": "2Rj0gc9u0SkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# for c,filee in reversed(list(enumerate(os.listdir('/content/drive/MyDrive/SEproject/Phase3/Contagio/MALWARE_PDF_PRE_04-2011_10982_files')))):\n",
        "#     if filee.endswith(\".png\"):\n",
        "#       src=os.path.join(\"/content/drive/MyDrive/SEproject/Phase3/Contagio/MALWARE_PDF_PRE_04-2011_10982_files\",filee)\n",
        "#       dst=\"/content/drive/MyDrive/SEproject/Phase3/Contagio/Test\"\n",
        "#       TrainPath=\"/content/drive/MyDrive/SEproject/Phase3/Contagio/Train\"\n",
        "#       if os.path.exists(os.path.join(dst,filee))==False and os.path.exists(os.path.join(TrainPath,filee))==False:\n",
        "#         #print(\"aloo\")\n",
        "#         shutil.copy(src, dst)\n",
        "#         #x=x+1\n",
        "#     if c==6750:\n",
        "#       break\n"
      ],
      "metadata": {
        "id": "MxOhK-GP0XgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UI funcs"
      ],
      "metadata": {
        "id": "LDHObkLWeVWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def clear():\n",
        "    \"\"\"Clear screen, return cursor to top left\"\"\"\n",
        "    sys.stdout.write('\\033[2J')\n",
        "    sys.stdout.write('\\033[H')\n",
        "    sys.stdout.flush()\n",
        "\n",
        "def prompt(msg=\"Select an option:\", options=[]):\n",
        "    \"\"\"Ask user to select an option or response\"\"\"\n",
        "    while True:\n",
        "        print(\"\\n\" + msg)\n",
        "        count = 0\n",
        "        for option in options:\n",
        "            print(\"\\t{}) {}\".format(count, option))\n",
        "            count += 1\n",
        "        res = input(\" > \")\n",
        "\n",
        "        try:\n",
        "            if  len(options) == 0 or int(res) < len(options):\n",
        "                return res\n",
        "            else:\n",
        "                print(\"Please select a number between 0 and {}\".format(len(options)-1))\n",
        "        except:\n",
        "            print(\"Please provide a valid response\")\n"
      ],
      "metadata": {
        "id": "W1E7zReQeYeE"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-processing funcs"
      ],
      "metadata": {
        "id": "_BuvVnj5dyw2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def getDims(f):\n",
        "    \"\"\"Returns (width, height) of byte plot image\"\"\"\n",
        "    size = len(f) * .001\n",
        "    if (size <= 10):\n",
        "        width = 32\n",
        "    elif (size <= 30):\n",
        "        width = 64\n",
        "    elif (size <= 60):\n",
        "        width = 128\n",
        "    elif (size <= 100):\n",
        "        width = 256\n",
        "    elif (size <= 200):\n",
        "        width = 384\n",
        "    elif (size <= 500):\n",
        "        width = 512\n",
        "    elif (size <= 1000):\n",
        "        width = 768\n",
        "    else:\n",
        "        width = 1024\n",
        "    return (width, math.ceil(size*1000 // width)+ 1)\n",
        "\n",
        "def bytePlot(f):\n",
        "    \"\"\"Creates byte plot from byte array. Returns image array\"\"\"\n",
        "    dimensions = getDims(f)\n",
        "    data = np.array(f)\n",
        "    data = np.pad(\n",
        "        data, (0, dimensions[0]-(len(data)%dimensions[0])), 'constant')\n",
        "    data = np.reshape(data, (-1, dimensions[0]))\n",
        "    return data\n",
        "\n",
        "\n",
        "\n",
        "def buildImages(files, targets):#, type):\n",
        "    \"\"\"Builds images from array of filenames. Returns (images, targets)\"\"\"\n",
        "    images = []\n",
        "    for file in files:\n",
        "        targets.append(file)\n",
        "        with open(file, \"rb\") as f:\n",
        "            #if type == \"Byte\":\n",
        "            images.append(bytePlot(list(f.read())))\n",
        "            # elif type == \"Markov\":\n",
        "            #     images.append(markovPlot(list(f.read())))\n",
        "            # elif type == \"Hilbert\":\n",
        "            #     images.append(hilbertPlot(list(f.read())))\n",
        "            #smp.imsave()\n",
        "            #images= np.array(images, dtype=np.uint8)\n",
        "            #images = images.astype(np.uint8)\n",
        "            #smp.imsave(\"{}.png\".format(file), images[-1])\n",
        "            imageio.imwrite(\"{}.png\".format(file), images[-1])\n",
        "\n",
        "    return images, targets\n",
        "\n",
        "def loadImages(files, targets):\n",
        "    \"\"\"Loads an array of png images. Returns (images, targets)\"\"\"\n",
        "    images = []\n",
        "    for file in files:\n",
        "        targets.append(file)\n",
        "        images.append(cv2.imread(file))\n",
        "    return images, targets\n",
        "\n",
        "def imagePages(files, choice):\n",
        "    \"\"\"Pages images into npy file in groups of 100\"\"\"\n",
        "    \n",
        "    targets = []\n",
        "    pageNames = []\n",
        "    pageSize = 100\n",
        "    pages = range(math.ceil(len(files)/pageSize))\n",
        "    for page in pb.progressbar(pages):\n",
        "        gc.collect() # Garbage collect\n",
        "\n",
        "        images = []\n",
        "        start = page*pageSize\n",
        "        if choice == \"Create\":\n",
        "            images, targets = buildImages(files[start:start+pageSize], targets)#, type)\n",
        "        elif choice == \"Load\":\n",
        "            images, targets = loadImages(files[start:start+pageSize], targets)\n",
        "        \n",
        "        pageNames.append(\"images_page{}.npy\".format(page))\n",
        "        np.save(pageNames[-1], images)\n",
        "    return targets, pageNames\n",
        "\n",
        "def process(directory): \n",
        "    \"\"\"Process each file in a directory, saving or loading images as directed\"\"\"\n",
        "    files = []\n",
        "\n",
        "    options = [\"Load\", \"Create\"]\n",
        "    choice = options[int(prompt(options=options))]\n",
        "\n",
        "    for item in os.listdir(directory):\n",
        "        if os.path.isfile(os.path.join(directory, item)):\n",
        "            filename = os.path.join(directory, item)\n",
        "            if choice == \"Load\" and item.endswith(\".png\"):\n",
        "                files.append(filename)\n",
        "            elif choice == \"Create\" and item.endswith(\".pdf\"):\n",
        "                files.append(filename)\n",
        "\n",
        "    filenames, pageNames = imagePages(files, choice)\n",
        "    \n",
        "    targets = [name.split('/')[-1][:5] for name in filenames]\n",
        "    return pageNames, targets, filenames"
      ],
      "metadata": {
        "id": "afQ0EeIreHGT"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature extraction funcs"
      ],
      "metadata": {
        "id": "RlLjjCimfuh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_feats(image, kernels):\n",
        "    \"\"\"Create feature vector from gabor kernels and image\"\"\"\n",
        "    feats = np.zeros((len(kernels), 2), dtype=np.double)\n",
        "    for k, kernel in enumerate(kernels):\n",
        "        filtered = nd.convolve(image, kernel, mode='wrap')\n",
        "        feats[k, 0] = filtered.mean()\n",
        "        feats[k, 1] = filtered.var()\n",
        "    return feats\n",
        "\n",
        "def describe_keypoints(img, alg, vector_size, descriptor_size, display=False):\n",
        "    \"\"\"Create description vector for keypoints in an image\"\"\"\n",
        "    # Finding image keypoints\n",
        "    kps = []\n",
        "    try:\n",
        "        kps = alg.detect(img, None)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # Get first sorted <vector_size> points.\n",
        "    kps = sorted(kps, key=lambda x: x.response)[:vector_size]\n",
        "    dsc = np.zeros((2, 2))\n",
        "    if len(kps) > 0: # Don't compute if no keypoints were found\n",
        "        kps, dsc = alg.compute(img, kps)\n",
        "\n",
        "    # Fill with zeros if no keypoints are found\n",
        "    if len(kps) < vector_size:\n",
        "        dsc = np.zeros(shape=(vector_size, descriptor_size))\n",
        "\n",
        "    # Flatten and normalize descriptors\n",
        "    dsc = dsc.flatten()\n",
        "    dsc = np.divide(dsc, 256)\n",
        "\n",
        "    return dsc\n",
        "\n",
        "\n",
        "def extract_SIFT(img):\n",
        "    #img = img.astype(np.uint8)\n",
        "    alg = cv2.xfeatures2d.SIFT_create()\n",
        "    vector_size = 32\n",
        "    descriptor_size = 128\n",
        "    return describe_keypoints(img, alg, vector_size, descriptor_size)"
      ],
      "metadata": {
        "id": "6Vq918mJfxtX"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def features(pageNames):\n",
        "    \"\"\"Loop through images, extracting desired features\"\"\"\n",
        "    \n",
        "    print(\"Should take less than {} minutes.\".format(len(pageNames)*2))\n",
        "    print(\"Please wait...\\n\")\n",
        "\n",
        "    # Run this with a pool of 3 agents until finished\n",
        "    data = []\n",
        "    for pageName in pb.progressbar(pageNames):\n",
        "        gc.collect()\n",
        "        np_load_old = np.load\n",
        "        np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
        "        images = np.load(pageName)\n",
        "        np.load = np_load_old\n",
        "       \n",
        "        with Pool(processes=3) as pool:\n",
        "            if len(data) == 0:\n",
        "                data = pool.map(extract_SIFT, images, 16)\n",
        "            else:\n",
        "                data = np.concatenate((data, pool.map(extract_SIFT, images, 16)))\n",
        "        # Remove paged files (to clear up disk space)\n",
        "        os.unlink(pageName)\n",
        "    \n",
        "    return data "
      ],
      "metadata": {
        "id": "29Wtm6sFf3OE"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training funcs"
      ],
      "metadata": {
        "id": "TmrNWayOgSk1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def save_filenames(y_true, y_pred, filenames):\n",
        "    \"\"\"Save filenames sorted by confusion matrix\"\"\"\n",
        "    tp = []\n",
        "    tn = []\n",
        "    fp = []\n",
        "    fn = []\n",
        "    prefix = str(random.randrange(1000000, 9999999))\n",
        "    for i in range(len(y_true)):\n",
        "        if not y_true[i] and not y_pred[i]:\n",
        "            tp.append(filenames[i])\n",
        "        elif y_true[i] and y_pred[i]:\n",
        "            tn.append(filenames[i])\n",
        "        elif not y_true[i] and y_pred[i]:\n",
        "            fn.append(filenames[i])\n",
        "        elif y_true[i] and not y_pred[i]:\n",
        "            fp.append(filenames[i])\n",
        "    np.savetxt(\"/content/drive/MyDrive/SEproject/Phase3/{}_true_pos.txt\".format(prefix), tp, delimiter=\",\", fmt=\"%s\")\n",
        "    np.savetxt(\"/content/drive/MyDrive/SEproject/Phase3/{}_true_neg.txt\".format(prefix), tn, delimiter=\",\", fmt=\"%s\")\n",
        "    np.savetxt(\"/content/drive/MyDrive/SEproject/Phase3/{}_false_pos.txt\".format(prefix), fp, delimiter=\",\", fmt=\"%s\")\n",
        "    np.savetxt(\"/content/drive/MyDrive/SEproject/Phase3/{}_false_neg.txt\".format(prefix), fn, delimiter=\",\", fmt=\"%s\")\n",
        "    return 0\n",
        "\n",
        "def true_neg(y_true, y_pred, args=None):\n",
        "    \"\"\"Count number of true negatives\"\"\"\n",
        "    fp_count = 0\n",
        "    for i in range(len(y_true)):\n",
        "        if not y_true[i] and not y_pred[i]:\n",
        "            fp_count += 1\n",
        "    return fp_count\n",
        "\n",
        "def true_pos(y_true, y_pred, args=None):\n",
        "    \"\"\"Count number of true positives\"\"\"\n",
        "    fp_count = 0\n",
        "    for i in range(len(y_true)):\n",
        "        if y_true[i] and y_pred[i]:\n",
        "            fp_count += 1\n",
        "    return fp_count\n",
        "\n",
        "def false_pos(y_true, y_pred, args=None):\n",
        "    \"\"\"Count number of false positives\"\"\"\n",
        "    fp_count = 0\n",
        "    for i in range(len(y_true)):\n",
        "        if not y_true[i] and y_pred[i]:\n",
        "            fp_count += 1\n",
        "    return fp_count\n",
        "\n",
        "def false_neg(y_true, y_pred, args=None):\n",
        "    \"\"\"Count number of false negatives\"\"\"\n",
        "    fn_count = 0\n",
        "    for i in range(len(y_true)):\n",
        "        if y_true[i] and not y_pred[i]:\n",
        "            fn_count += 1\n",
        "    return fn_count\n",
        "\n",
        "def model_evaluation(data, targets, clf):    \n",
        "    # Cross validate and calculate scores\n",
        "    f_pos = skm.make_scorer(false_pos)\n",
        "    f_neg = skm.make_scorer(false_neg)\n",
        "    t_pos = skm.make_scorer(true_pos)\n",
        "    t_neg = skm.make_scorer(true_neg)\n",
        "    scoring = {\n",
        "            \"accuracy\": \"accuracy\",\n",
        "            \"precision\": \"precision\",\n",
        "            \"recall\": \"recall\",\n",
        "            \"f1\": \"f1\",\n",
        "            \"f_pos\": f_pos,\n",
        "            \"f_neg\": f_neg,\n",
        "            \"t_pos\": t_pos,\n",
        "            \"t_neg\": t_neg,\n",
        "    }\n",
        "    scores = cross_validate(clf, data, targets, scoring=scoring, cv=10)\n",
        "    print(\"Scores calculated from 10-fold cross validation:\")\n",
        "    print(\"Accuracy:  {},\\t{}\".format(round(np.mean(scores[\"test_accuracy\"]),  4), scores[\"test_accuracy\"]))\n",
        "    print(\"Precision: {},\\t{}\".format(round(np.mean(scores[\"test_precision\"]), 4), scores[\"test_precision\"]))\n",
        "    print(\"Recall:    {},\\t{}\".format(round(np.mean(scores[\"test_recall\"]),    4), scores[\"test_recall\"]))\n",
        "    print(\"F1:        {},\\t{}\".format(round(np.mean(scores[\"test_f1\"]),        4), scores[\"test_f1\"]))\n",
        "    print(\"False Pos: {},\\t{}\".format(round(np.mean(scores[\"test_f_pos\"]),     4), scores[\"test_f_pos\"]))\n",
        "    print(\"False Neg: {},\\t{}\".format(round(np.mean(scores[\"test_f_neg\"]),     4), scores[\"test_f_neg\"]))\n",
        "    print(\"True Pos:  {},\\t{}\".format(round(np.mean(scores[\"test_t_pos\"]),     4), scores[\"test_t_pos\"]))\n",
        "    print(\"True Neg:  {},\\t{}\".format(round(np.mean(scores[\"test_t_neg\"]),     4), scores[\"test_t_neg\"]))\n",
        "\n",
        "def train(data, targets, filenames):\n",
        "    targets = [val == \"INFEC\" for val in targets] # Set INFEC as positive val\n",
        "   \n",
        "    # Choose training mode\n",
        "    options = [\"Cross validation\", \"Build and test model\"]\n",
        "    res = prompt(options=options)\n",
        "    mode = options[int(res)]\n",
        "\n",
        "    # Choose ML algorithm\n",
        "    options = [\"Support Vector Machine\", \"Random Forest\",\n",
        "            \"Decision Tree Classifier\", \"KNN\"]\n",
        "    res = prompt(\"Choose a ML algorithm:\", options)\n",
        "    switch = {\n",
        "        0: svm.SVC(C=100., random_state=0),\n",
        "        1: RandomForestClassifier(n_estimators=50, max_depth=None, random_state=0),\n",
        "        2: DecisionTreeClassifier(random_state=0),\n",
        "        3: KNeighborsClassifier()\n",
        "    }\n",
        "    clf = switch.get(int(res))\n",
        "   \n",
        "    if mode == \"Cross validation\":\n",
        "        model_evaluation(data, targets, clf)\n",
        "    elif mode == \"Build and test model\":\n",
        "        # Train model\n",
        "        clf.fit(data, targets)\n",
        "\n",
        "        # Get test dir\n",
        "        while True:\n",
        "            dirname = prompt(\"Which directory are the test files in?\")\n",
        "            if os.path.isdir(dirname):\n",
        "                break\n",
        "            print(\"ERROR: Directory not found.\")\n",
        "\n",
        "        # Set up data/targets for test model\n",
        "        print(\"\\n************************************\")\n",
        "        print(\"*  PREPARING MODEL FOR EVALUATION  *\")\n",
        "        print(\"************************************\")\n",
        "\n",
        "        pageNames, y_true, filenames = process(dirname)    \n",
        "        y_true = [val == \"INFEC\" for val in y_true] # Set INFEC as positive val\n",
        "        test_data = features(pageNames)\n",
        "   \n",
        "        y_pred = clf.predict(test_data)\n",
        "\n",
        "        save_filenames(y_true, y_pred, filenames)\n",
        "    \n",
        "        conf_matrix = skm.confusion_matrix(y_true, y_pred)\n",
        "        accuracy = skm.accuracy_score(y_true, y_pred)\n",
        "        precision = skm.precision_score(y_true, y_pred, average=None)\n",
        "        recall = skm.recall_score(y_true, y_pred, average=None)\n",
        "        f1 = skm.f1_score(y_true, y_pred, average=None)\n",
        "        print(\"\\n{}\".format(conf_matrix))\n",
        "        print(\"Accuracy:  {}\".format(accuracy))\n",
        "        print(\"Precision: {}\".format(precision[1]))\n",
        "        print(\"Recall:    {}\".format(recall[1]))\n",
        "        print(\"F1:        {}\".format(f1[1]))"
      ],
      "metadata": {
        "id": "x9-IjLBYgV_F"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Program"
      ],
      "metadata": {
        "id": "128Gb0X2gXgR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def main():\n",
        "    # Create images & extract features (until user quits)\n",
        "    doneExtracting = False\n",
        "    while not doneExtracting:\n",
        "        pageNames, targets, filenames = process('/content/drive/MyDrive/SEproject/Phase3/Contagio/Train')#directory\n",
        "        data = features(pageNames)\n",
        "\n",
        "        # Create and evaluate model (until user quits)\n",
        "        doneTraining = False\n",
        "        while not doneTraining:\n",
        "            train(data, targets, filenames)\n",
        "            \n",
        "            options = [\"Try another model\", \"Extract new features\", \"Quit\"]\n",
        "            res = options[int(prompt(options=options))]\n",
        "            if res == \"Quit\":\n",
        "                doneTraining = True\n",
        "                doneExtracting = True\n",
        "            elif res == \"Extract new features\":\n",
        "                doneTraining = True\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "#Test dir\n",
        "#/content/drive/MyDrive/SEproject/Phase3/Contagio/Test"
      ],
      "metadata": {
        "id": "B1jp9FkCgdC4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f3be6e9-119b-4d6d-f8c4-2e6bf047a0a4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Select an option:\n",
            "\t0) Load\n",
            "\t1) Create\n",
            " > 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "N/A% (0 of 102) |                        | Elapsed Time: 0:00:00 ETA:  --:--:--/usr/local/lib/python3.8/dist-packages/numpy/lib/npyio.py:528: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  arr = np.asanyarray(arr)\n",
            "100% (102 of 102) |######################| Elapsed Time: 0:31:01 Time:  0:31:01\n",
            "N/A% (0 of 102) |                        | Elapsed Time: 0:00:00 ETA:  --:--:--"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Should take less than 204 minutes.\n",
            "Please wait...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100% (102 of 102) |######################| Elapsed Time: 0:06:10 Time:  0:06:10\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Select an option:\n",
            "\t0) Cross validation\n",
            "\t1) Build and test model\n",
            " > 1\n",
            "\n",
            "Choose a ML algorithm:\n",
            "\t0) Support Vector Machine\n",
            "\t1) Random Forest\n",
            "\t2) Decision Tree Classifier\n",
            "\t3) KNN\n",
            " > 1\n",
            "\n",
            "Which directory are the test files in?\n",
            " > /content/drive/MyDrive/SEproject/Phase3/Contagio/Test\n",
            "\n",
            "************************************\n",
            "*  PREPARING MODEL FOR EVALUATION  *\n",
            "************************************\n",
            "\n",
            "Select an option:\n",
            "\t0) Load\n",
            "\t1) Create\n",
            " > 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "N/A% (0 of 35) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--/usr/local/lib/python3.8/dist-packages/numpy/lib/npyio.py:528: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  arr = np.asanyarray(arr)\n",
            "100% (35 of 35) |########################| Elapsed Time: 0:01:06 Time:  0:01:06\n",
            "N/A% (0 of 35) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Should take less than 70 minutes.\n",
            "Please wait...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100% (35 of 35) |########################| Elapsed Time: 0:03:13 Time:  0:03:13\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[[2213   37]\n",
            " [ 317  890]]\n",
            "Accuracy:  0.897599074341915\n",
            "Precision: 0.9600862998921251\n",
            "Recall:    0.7373653686826843\n",
            "F1:        0.8341143392689785\n",
            "\n",
            "Select an option:\n",
            "\t0) Try another model\n",
            "\t1) Extract new features\n",
            "\t2) Quit\n",
            " > 0\n",
            "\n",
            "Select an option:\n",
            "\t0) Cross validation\n",
            "\t1) Build and test model\n",
            " > 1\n",
            "\n",
            "Choose a ML algorithm:\n",
            "\t0) Support Vector Machine\n",
            "\t1) Random Forest\n",
            "\t2) Decision Tree Classifier\n",
            "\t3) KNN\n",
            " > 0\n",
            "\n",
            "Which directory are the test files in?\n",
            " > /content/drive/MyDrive/SEproject/Phase3/Contagio/Test\n",
            "\n",
            "************************************\n",
            "*  PREPARING MODEL FOR EVALUATION  *\n",
            "************************************\n",
            "\n",
            "Select an option:\n",
            "\t0) Load\n",
            "\t1) Create\n",
            " > 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "N/A% (0 of 35) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--/usr/local/lib/python3.8/dist-packages/numpy/lib/npyio.py:528: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  arr = np.asanyarray(arr)\n",
            "100% (35 of 35) |########################| Elapsed Time: 0:00:26 Time:  0:00:26\n",
            "N/A% (0 of 35) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Should take less than 70 minutes.\n",
            "Please wait...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100% (35 of 35) |########################| Elapsed Time: 0:03:04 Time:  0:03:04\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[[2217   33]\n",
            " [ 134 1073]]\n",
            "Accuracy:  0.9516922186867226\n",
            "Precision: 0.9701627486437613\n",
            "Recall:    0.8889809444904723\n",
            "F1:        0.9277993947254648\n",
            "\n",
            "Select an option:\n",
            "\t0) Try another model\n",
            "\t1) Extract new features\n",
            "\t2) Quit\n",
            " > 0\n",
            "\n",
            "Select an option:\n",
            "\t0) Cross validation\n",
            "\t1) Build and test model\n",
            " > 1\n",
            "\n",
            "Choose a ML algorithm:\n",
            "\t0) Support Vector Machine\n",
            "\t1) Random Forest\n",
            "\t2) Decision Tree Classifier\n",
            "\t3) KNN\n",
            " > 2\n",
            "\n",
            "Which directory are the test files in?\n",
            " > /content/drive/MyDrive/SEproject/Phase3/Contagio/Test\n",
            "\n",
            "************************************\n",
            "*  PREPARING MODEL FOR EVALUATION  *\n",
            "************************************\n",
            "\n",
            "Select an option:\n",
            "\t0) Load\n",
            "\t1) Create\n",
            " > 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "N/A% (0 of 35) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--/usr/local/lib/python3.8/dist-packages/numpy/lib/npyio.py:528: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  arr = np.asanyarray(arr)\n",
            "100% (35 of 35) |########################| Elapsed Time: 0:00:26 Time:  0:00:26\n",
            "N/A% (0 of 35) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Should take less than 70 minutes.\n",
            "Please wait...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100% (35 of 35) |########################| Elapsed Time: 0:03:05 Time:  0:03:05\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[[1821  429]\n",
            " [ 336  871]]\n",
            "Accuracy:  0.7787098640439688\n",
            "Precision: 0.67\n",
            "Recall:    0.7216238608119304\n",
            "F1:        0.6948544076585561\n",
            "\n",
            "Select an option:\n",
            "\t0) Try another model\n",
            "\t1) Extract new features\n",
            "\t2) Quit\n",
            " > 0\n",
            "\n",
            "Select an option:\n",
            "\t0) Cross validation\n",
            "\t1) Build and test model\n",
            " > 1\n",
            "\n",
            "Choose a ML algorithm:\n",
            "\t0) Support Vector Machine\n",
            "\t1) Random Forest\n",
            "\t2) Decision Tree Classifier\n",
            "\t3) KNN\n",
            " > 3\n",
            "\n",
            "Which directory are the test files in?\n",
            " > /content/drive/MyDrive/SEproject/Phase3/Contagio/Test\n",
            "\n",
            "************************************\n",
            "*  PREPARING MODEL FOR EVALUATION  *\n",
            "************************************\n",
            "\n",
            "Select an option:\n",
            "\t0) Load\n",
            "\t1) Create\n",
            " > 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "N/A% (0 of 35) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--/usr/local/lib/python3.8/dist-packages/numpy/lib/npyio.py:528: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  arr = np.asanyarray(arr)\n",
            "100% (35 of 35) |########################| Elapsed Time: 0:00:24 Time:  0:00:24\n",
            "N/A% (0 of 35) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Should take less than 70 minutes.\n",
            "Please wait...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100% (35 of 35) |########################| Elapsed Time: 0:03:12 Time:  0:03:12\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[[ 941 1309]\n",
            " [  57 1150]]\n",
            "Accuracy:  0.6048597049464854\n",
            "Precision: 0.4676697844652298\n",
            "Recall:    0.9527754763877382\n",
            "F1:        0.6273867975995635\n",
            "\n",
            "Select an option:\n",
            "\t0) Try another model\n",
            "\t1) Extract new features\n",
            "\t2) Quit\n",
            " > 2\n"
          ]
        }
      ]
    }
  ]
}