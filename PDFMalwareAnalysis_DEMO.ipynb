{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "QO3A7o4_DJob"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "PDF MALWARE ANALYSIS SYSTEM USING IMAGE PROCESSING"
      ],
      "metadata": {
        "id": "hmepTFlG4wXT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing libs"
      ],
      "metadata": {
        "id": "GN9crajHdurt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Z1AK28EAdb7U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84644d4f-5994-488a-e94f-72b2ec8c27cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scipy"
      ],
      "metadata": {
        "id": "IKDsc82QoNzy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "049247f9-65b5-4994-af43-689f71353a84"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from scipy) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "#####\n",
        "import numpy as np\n",
        "#import scipy.misc as smp # Save images\n",
        "import scipy.ndimage as snd # Load images\n",
        "import math # Aids \"length\" variable\n",
        "import progressbar as pb\n",
        "from math import isinf\n",
        "import os\n",
        "import gc\n",
        "####\n",
        "\n",
        "from multiprocessing import Pool\n",
        "\n",
        "import scipy.misc as smp # Save images\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import cv2 #SIFT\n",
        "from scipy import ndimage as nd # For convolving kernel\n",
        "from skimage import exposure # For creating histogram\n",
        "from skimage.util import img_as_float \n",
        "from skimage.feature import local_binary_pattern\n",
        "from skimage.filters import gabor_kernel\n",
        "from skimage.filters.rank import entropy\n",
        "from skimage.morphology import disk \n",
        "\n",
        "####################\n",
        "\n",
        "\n",
        "import random\n",
        "\n",
        "# ML Classifiers\n",
        "from sklearn import svm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Model evaluation\n",
        "from sklearn.model_selection import cross_validate\n",
        "import sklearn.metrics as skm\n",
        "\n",
        "import imageio\n",
        "import PIL\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "  "
      ],
      "metadata": {
        "id": "-2llnRA7dsL3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Directories"
      ],
      "metadata": {
        "id": "QO3A7o4_DJob"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rename PDF files to extract label from file name"
      ],
      "metadata": {
        "id": "1lhUn5Rj4Lqf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# for filee in os.listdir('/content/drive/MyDrive/SEproject/Phase3/Contagio/CLEAN_PDF_9000_files'):\n",
        "# \tsrc=os.path.join(\"/content/drive/MyDrive/SEproject/Phase3/Contagio/CLEAN_PDF_9000_files\",filee)\n",
        "# \tdst=f\"/content/drive/MyDrive/SEproject/Phase3/Contagio/CLEAN_PDF_9000_files/CLEAN_{filee}\"\n",
        "# \tos.rename(src, dst)\n",
        "# \t#shutil.copy(os.path.join(path_of_files_folders, filee), destination)\n",
        "# #os.rename('/content/drive/MyDrive/SEproject/Phase3/Contagio/CLEAN_PDF_9000_files/CLEAN_0_ea-2a_1108.pdf','/content/drive/MyDrive/SEproject/Phase3/Contagio/CLEAN_PDF_9000_files/0_ea-2a_1108.pdf')"
      ],
      "metadata": {
        "id": "jQGMNtaCH7Q8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# for filee in os.listdir('/content/drive/MyDrive/SEproject/Phase3/Contagio/MALWARE_PDF_PRE_04-2011_10982_files'):\n",
        "# \tsrc=os.path.join(\"/content/drive/MyDrive/SEproject/Phase3/Contagio/MALWARE_PDF_PRE_04-2011_10982_files\",filee)\n",
        "# \tdst=f\"/content/drive/MyDrive/SEproject/Phase3/Contagio/MALWARE_PDF_PRE_04-2011_10982_files/INFEC_{filee}\"\n",
        "# \tos.rename(src, dst)"
      ],
      "metadata": {
        "id": "566hWMe7bLv-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   Train: 10,500 file (5,250 benign & 5,250 malicious)\n",
        "*   Test: 4,500 file (2,250 benign & 2,250 malicious)\n",
        "\n",
        "*  Total dataset: 15,000 with a 70:30 split\n"
      ],
      "metadata": {
        "id": "3JBR-rbFzyX2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train 70%"
      ],
      "metadata": {
        "id": "BHjmwZ_A0IaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Benign\n",
        "\n",
        "# c=0\n",
        "# for c,filee in enumerate(os.listdir('/content/drive/MyDrive/SEproject/Phase3/Contagio/CLEAN_PDF_9000_files')):\n",
        "#   if filee.endswith(\".png\"):\n",
        "#     src=os.path.join(\"/content/drive/MyDrive/SEproject/Phase3/Contagio/CLEAN_PDF_9000_files\",filee)\n",
        "#     dst=\"/content/drive/MyDrive/SEproject/Phase3/Contagio/Train\"\n",
        "#     shutil.copy(src, dst)\n",
        "#   if c==5250:\n",
        "#     break\n",
        "\n",
        "# print(c)"
      ],
      "metadata": {
        "id": "_wO6gW2l0DDX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #Malicious\n",
        "# c=0\n",
        "# for c,filee in enumerate(os.listdir('/content/drive/MyDrive/SEproject/Phase3/Contagio/MALWARE_PDF_PRE_04-2011_10982_files')):\n",
        "#   if filee.endswith(\".png\"):\n",
        "#     src=os.path.join(\"/content/drive/MyDrive/SEproject/Phase3/Contagio/MALWARE_PDF_PRE_04-2011_10982_files\",filee)\n",
        "#     dst=\"/content/drive/MyDrive/SEproject/Phase3/Contagio/Train\"\n",
        "#     shutil.copy(src, dst)\n",
        "#     if c==5250:\n",
        "#       break"
      ],
      "metadata": {
        "id": "hlWNWTvB0Fxg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test 30%"
      ],
      "metadata": {
        "id": "JHGVCzCt0Jv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# for c,filee in reversed(list(enumerate(os.listdir('/content/drive/MyDrive/SEproject/Phase3/Contagio/CLEAN_PDF_9000_files')))):\n",
        "#     if filee.endswith(\".png\"):\n",
        "#       src=os.path.join(\"/content/drive/MyDrive/SEproject/Phase3/Contagio/CLEAN_PDF_9000_files\",filee)\n",
        "#       TestPath=\"/content/drive/MyDrive/SEproject/Phase3/Contagio/Test\"\n",
        "#       TrainPath=\"/content/drive/MyDrive/SEproject/Phase3/Contagio/Train\"\n",
        "#       if os.path.exists(os.path.join(TestPath,filee))==False and os.path.exists(os.path.join(TrainPath,filee))==False:\n",
        "#         shutil.copy(src, TestPath)\n",
        "#     if c==6750:\n",
        "#       break\n"
      ],
      "metadata": {
        "id": "2Rj0gc9u0SkS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# for c,filee in reversed(list(enumerate(os.listdir('/content/drive/MyDrive/SEproject/Phase3/Contagio/MALWARE_PDF_PRE_04-2011_10982_files')))):\n",
        "#     if filee.endswith(\".png\"):\n",
        "#       src=os.path.join(\"/content/drive/MyDrive/SEproject/Phase3/Contagio/MALWARE_PDF_PRE_04-2011_10982_files\",filee)\n",
        "#       dst=\"/content/drive/MyDrive/SEproject/Phase3/Contagio/Test\"\n",
        "#       TrainPath=\"/content/drive/MyDrive/SEproject/Phase3/Contagio/Train\"\n",
        "#       if os.path.exists(os.path.join(dst,filee))==False and os.path.exists(os.path.join(TrainPath,filee))==False:\n",
        "#         #print(\"aloo\")\n",
        "#         shutil.copy(src, dst)\n",
        "#         #x=x+1\n",
        "#     if c==6750:\n",
        "#       break\n"
      ],
      "metadata": {
        "id": "MxOhK-GP0XgF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UI funcs"
      ],
      "metadata": {
        "id": "LDHObkLWeVWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def clear():\n",
        "    \"\"\"Clear screen, return cursor to top left\"\"\"\n",
        "    sys.stdout.write('\\033[2J')\n",
        "    sys.stdout.write('\\033[H')\n",
        "    sys.stdout.flush()\n",
        "\n",
        "def prompt(msg=\"Select an option:\", options=[]):\n",
        "    \"\"\"Ask user to select an option or response\"\"\"\n",
        "    while True:\n",
        "        print(\"\\n\" + msg)\n",
        "        count = 0\n",
        "        for option in options:\n",
        "            print(\"\\t{}) {}\".format(count, option))\n",
        "            count += 1\n",
        "        res = input(\" > \")\n",
        "\n",
        "        try:\n",
        "            if  len(options) == 0 or int(res) < len(options):\n",
        "                return res\n",
        "            else:\n",
        "                print(\"Please select a number between 0 and {}\".format(len(options)-1))\n",
        "        except:\n",
        "            print(\"Please provide a valid response\")\n"
      ],
      "metadata": {
        "id": "W1E7zReQeYeE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-processing funcs"
      ],
      "metadata": {
        "id": "_BuvVnj5dyw2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def getDims(f):\n",
        "    \"\"\"Returns (width, height) of byte plot image\"\"\"\n",
        "    size = len(f) * .001\n",
        "    if (size <= 10):\n",
        "        width = 32\n",
        "    elif (size <= 30):\n",
        "        width = 64\n",
        "    elif (size <= 60):\n",
        "        width = 128\n",
        "    elif (size <= 100):\n",
        "        width = 256\n",
        "    elif (size <= 200):\n",
        "        width = 384\n",
        "    elif (size <= 500):\n",
        "        width = 512\n",
        "    elif (size <= 1000):\n",
        "        width = 768\n",
        "    else:\n",
        "        width = 1024\n",
        "    return (width, math.ceil(size*1000 // width)+ 1)\n",
        "\n",
        "def bytePlot(f):\n",
        "    \"\"\"Creates byte plot from byte array. Returns image array\"\"\"\n",
        "    dimensions = getDims(f)\n",
        "    data = np.array(f)\n",
        "    data = np.pad(\n",
        "        data, (0, dimensions[0]-(len(data)%dimensions[0])), 'constant')\n",
        "    data = np.reshape(data, (-1, dimensions[0]))\n",
        "    return data\n",
        "\n",
        "\n",
        "\n",
        "def buildImages(files, targets):\n",
        "    \"\"\"Builds images from array of filenames. Returns (images, targets)\"\"\"\n",
        "    images = []\n",
        "    for file in files:\n",
        "        targets.append(file)\n",
        "        with open(file, \"rb\") as f:\n",
        "            \n",
        "            images.append(bytePlot(list(f.read())))\n",
        "            \n",
        "            imageio.imwrite(\"{}.png\".format(file), images[-1])\n",
        "\n",
        "    return images, targets\n",
        "\n",
        "def loadImages(files, targets):\n",
        "    \"\"\"Loads an array of png images. Returns (images, targets)\"\"\"\n",
        "    images = []\n",
        "    for file in files:\n",
        "        targets.append(file)\n",
        "        images.append(cv2.imread(file))\n",
        "    return images, targets\n",
        "\n",
        "def imagePages(files, choice):\n",
        "    \"\"\"Pages images into npy file in groups of 100\"\"\"\n",
        "    \n",
        "    targets = []\n",
        "    pageNames = []\n",
        "    pageSize = 100\n",
        "    pages = range(math.ceil(len(files)/pageSize))\n",
        "    for page in pb.progressbar(pages):\n",
        "        gc.collect() # Garbage collect\n",
        "\n",
        "        images = []\n",
        "        start = page*pageSize\n",
        "        if choice == \"Create\":\n",
        "            images, targets = buildImages(files[start:start+pageSize], targets)#, type)\n",
        "        elif choice == \"Load\":\n",
        "            images, targets = loadImages(files[start:start+pageSize], targets)\n",
        "        \n",
        "        pageNames.append(\"images_page{}.npy\".format(page))\n",
        "        np.save(pageNames[-1], images)\n",
        "    return targets, pageNames\n",
        "\n",
        "def process(directory): \n",
        "    \"\"\"Process each file in a directory, saving or loading images as directed\"\"\"\n",
        "    files = []\n",
        "\n",
        "    options = [\"Load\", \"Create\"]\n",
        "    choice = options[int(prompt(options=options))]\n",
        "\n",
        "    for item in os.listdir(directory):\n",
        "        if os.path.isfile(os.path.join(directory, item)):\n",
        "            filename = os.path.join(directory, item)\n",
        "            if choice == \"Load\" and item.endswith(\".png\"):\n",
        "                files.append(filename)\n",
        "            elif choice == \"Create\" and item.endswith(\".pdf\"):\n",
        "                files.append(filename)\n",
        "\n",
        "    filenames, pageNames = imagePages(files, choice)\n",
        "    \n",
        "    targets = [name.split('/')[-1][:5] for name in filenames]\n",
        "    return pageNames, targets, filenames"
      ],
      "metadata": {
        "id": "afQ0EeIreHGT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature extraction funcs"
      ],
      "metadata": {
        "id": "RlLjjCimfuh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def describe_keypoints(img, alg, vector_size, descriptor_size, display=False):\n",
        "    \"\"\"Create description vector for keypoints in an image\"\"\"\n",
        "    # Finding image keypoints\n",
        "    kps = []\n",
        "    try:\n",
        "        kps = alg.detect(img, None)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # Get first sorted <vector_size> points.\n",
        "    kps = sorted(kps, key=lambda x: x.response)[:vector_size]\n",
        "    dsc = np.zeros((2, 2))\n",
        "    if len(kps) > 0: # Don't compute if no keypoints were found\n",
        "        kps, dsc = alg.compute(img, kps)\n",
        "\n",
        "    # Fill with zeros if no keypoints are found\n",
        "    if len(kps) < vector_size:\n",
        "        dsc = np.zeros(shape=(vector_size, descriptor_size))\n",
        "\n",
        "    # Flatten and normalize descriptors\n",
        "    dsc = dsc.flatten()\n",
        "    dsc = np.divide(dsc, 256)\n",
        "\n",
        "    return dsc\n",
        "\n",
        "\n",
        "def extract_SIFT(img):\n",
        "    #img = img.astype(np.uint8)\n",
        "    alg = cv2.xfeatures2d.SIFT_create()\n",
        "    vector_size = 32\n",
        "    descriptor_size = 128\n",
        "    return describe_keypoints(img, alg, vector_size, descriptor_size)"
      ],
      "metadata": {
        "id": "6Vq918mJfxtX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def features(pageNames):\n",
        "    \"\"\"Loop through images, extracting desired features\"\"\"\n",
        "    \n",
        "    print(\"Should take less than {} minutes.\".format(len(pageNames)*2))\n",
        "    print(\"Please wait...\\n\")\n",
        "\n",
        "    # Run this with a pool of 3 agents until finished\n",
        "    data = []\n",
        "    for pageName in pb.progressbar(pageNames):\n",
        "        gc.collect()\n",
        "        np_load_old = np.load\n",
        "        np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
        "        images = np.load(pageName)\n",
        "        np.load = np_load_old\n",
        "       \n",
        "        with Pool(processes=3) as pool:\n",
        "            if len(data) == 0:\n",
        "                data = pool.map(extract_SIFT, images, 16)\n",
        "            else:\n",
        "                data = np.concatenate((data, pool.map(extract_SIFT, images, 16)))\n",
        "        # Remove paged files (to clear up disk space)\n",
        "        os.unlink(pageName)\n",
        "    \n",
        "    return data "
      ],
      "metadata": {
        "id": "29Wtm6sFf3OE"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training funcs"
      ],
      "metadata": {
        "id": "TmrNWayOgSk1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def train(data, targets, filenames):\n",
        "    targets = [val == \"INFEC\" for val in targets] # Set INFEC as TRUE \n",
        "   \n",
        "    # Choose training mode\n",
        "    # options = [\"Cross validation\", \"Build and test model\"]\n",
        "    # res = prompt(options=options)\n",
        "    # mode = options[int(res)]\n",
        "\n",
        "    # Choose ML algorithm\n",
        "    options = [\"Support Vector Machine\", \"Random Forest\",\n",
        "            \"Decision Tree Classifier\", \"KNN\"]\n",
        "    res = prompt(\"Choose a ML algorithm:\", options)\n",
        "    \n",
        "    switch = {\n",
        "        0: '/content/drive/MyDrive/SEproject/Phase3/Implementation/models/SVM.sav',         \n",
        "        # svm.SVC(C=100., random_state=0) \n",
        "        1: '/content/drive/MyDrive/SEproject/Phase3/Implementation/models/RF.sav',\n",
        "        # RandomForestClassifier(n_estimators=50, max_depth=None, random_state=0)\n",
        "        2: '/content/drive/MyDrive/SEproject/Phase3/Implementation/models/DT.sav',\n",
        "          #DecisionTreeClassifier(random_state=0),\n",
        "        3: '/content/drive/MyDrive/SEproject/Phase3/Implementation/models/KNN.sav'\n",
        "         # KNeighborsClassifier(),\n",
        "          \n",
        "    }\n",
        "    \n",
        "\n",
        "    #clf = switch.get(int(res))\n",
        "    filename =  switch.get(int(res))\n",
        "   \n",
        "    # if mode == \"Cross validation\":\n",
        "    #   x=0\n",
        "        #model_evaluation(data, targets, clf)\n",
        "    # elif mode == \"Build and test model\":\n",
        "        # Train model\n",
        "        #clf.fit(data, targets)\n",
        "        \n",
        "        # Save the trained model as a pickle string.\n",
        "        #filename = '/content/drive/MyDrive/SEproject/Phase3/Implementation/models/SVM.sav'\n",
        "        #filename = '/content/drive/MyDrive/SEproject/Phase3/Implementation/models/RF.sav'\n",
        "        #filename= '/content/drive/MyDrive/SEproject/Phase3/Implementation/models/DT.sav'\n",
        "        #filename= '/content/drive/MyDrive/SEproject/Phase3/Implementation/models/KNN.sav'\n",
        "        \n",
        "        #pickle.dump(clf, open(filename, 'wb'))\n",
        "\n",
        "        # Load the pickled model\n",
        "    loaded_model = pickle.load(open(filename, 'rb'))\n",
        "      \n",
        "    # load the model from disk\n",
        "    \n",
        "    # result = loaded_model.score(X_test, Y_test)\n",
        "    # print(\"loaded model result:\"result)\n",
        "    # Get test dir\n",
        "    while True:\n",
        "        dirname = prompt(\"Which directory are the test files in?\")\n",
        "        if os.path.isdir(dirname):\n",
        "            break\n",
        "        print(\"ERROR: Directory not found.\")\n",
        "\n",
        "    # Set up data/targets for test model\n",
        "    print(\"\\n************************************\")\n",
        "    print(\"*  PREPARING MODEL FOR EVALUATION  *\")\n",
        "    print(\"************************************\")\n",
        "\n",
        "    pageNames, y_true, filenames = process(dirname)    \n",
        "    y_true = [val == \"INFEC\" for val in y_true] # Set INFEC as positive val\n",
        "    test_data = features(pageNames)\n",
        "\n",
        "\n",
        "    # loss, acc = loaded_model.evaluate(test_images, test_labels, verbose=2)\n",
        "    # print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))\n",
        "    # print(new_model.predict(test_images).shape)\n",
        "\n",
        "    y_pred = loaded_model.predict(test_data)\n",
        "\n",
        "    # Use the loaded pickled model to make predictions\n",
        "    # y_pred= loaded_model.predict(test_data)\n",
        "\n",
        "    \n",
        "    print(\"Prediction: \",y_pred)\n",
        "    conf_matrix = skm.confusion_matrix(y_true, y_pred)\n",
        "    accuracy = skm.accuracy_score(y_true, y_pred)\n",
        "    precision = skm.precision_score(y_true, y_pred, average=None)\n",
        "    recall = skm.recall_score(y_true, y_pred, average=None)\n",
        "    f1 = skm.f1_score(y_true, y_pred, average=None)\n",
        "    print(\"Confusion matrix:\\n{}\".format(conf_matrix))\n",
        "    print(\"Accuracy:  {}\".format(accuracy))\n",
        "    print(\"Precision: {}\".format(precision[1]))\n",
        "    print(\"Recall:    {}\".format(recall[1]))\n",
        "    print(\"F1:        {}\".format(f1[1]))"
      ],
      "metadata": {
        "id": "x9-IjLBYgV_F"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Program"
      ],
      "metadata": {
        "id": "128Gb0X2gXgR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def main():\n",
        "    print(\"\\n************************************\")\n",
        "    print(\"* PDF Image Malware Analysis System *\")\n",
        "    print(\"************************************\")\n",
        "    print('\\nUpload PDF')\n",
        "    # Create images & extract features (until user quits)\n",
        "    doneExtracting = False\n",
        "    while not doneExtracting:\n",
        "        pageNames, targets, filenames = process('/content/drive/MyDrive/SEproject/Phase3/Contagio/Train')#directory \n",
        "       \n",
        "        data = features(pageNames)\n",
        "\n",
        "        # Create and evaluate model (until user quits)\n",
        "        doneTraining = False\n",
        "        while not doneTraining:\n",
        "            train(data, targets, filenames)\n",
        "            \n",
        "            options = [\"Try another model\", \"Extract new features\", \"Quit\"]\n",
        "            res = options[int(prompt(options=options))]\n",
        "            if res == \"Quit\":\n",
        "                doneTraining = True\n",
        "                doneExtracting = True\n",
        "            elif res == \"Extract new features\":\n",
        "                doneTraining = True\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "\n",
        "#Train dir\n",
        "#/content/drive/MyDrive/SEproject/Phase3/Contagio/Train\n",
        "#/content/drive/MyDrive/SEproject/Phase3/Contagio/Train_sample\n",
        "\n",
        "#/content/drive/MyDrive/SEproject/Phase3/UserInput\n",
        "\n",
        "#Test dir\n",
        "#/content/drive/MyDrive/SEproject/Phase3/Contagio/Test\n",
        "#/content/drive/MyDrive/SEproject/Phase3/Contagio/Test_sample"
      ],
      "metadata": {
        "id": "B1jp9FkCgdC4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b2e361d-ad5e-49e4-86d3-1fcc2f0dd2ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "************************************\n",
            "* PDF Image Malware Analysis System *\n",
            "************************************\n",
            "\n",
            "Upload PDF\n",
            "\n",
            "Select an option:\n",
            "\t0) Load\n",
            "\t1) Create\n",
            " > 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "N/A% (0 of 102) |                        | Elapsed Time: 0:00:00 ETA:  --:--:--/usr/local/lib/python3.8/dist-packages/numpy/lib/npyio.py:528: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  arr = np.asanyarray(arr)\n",
            "  0% (1 of 102) |                        | Elapsed Time: 0:00:18 ETA:   0:30:57"
          ]
        }
      ]
    }
  ]
}